# Spark-in-practice
Quoi de mieux que des exemples issus de la pratique pour apprendre à développer avec Spark (Core, DataFrame, DataSet, SQL) ? Rien de mieux. Pour cela, nous allons traiter à l'aide de Spark des uses cases issus concernant la grande distribution.  

# Les jeux de données
Les données manipulées sont issues de la suite de test du moteur OLAP de Pentaho Mondrian.
Les données que nous manipulons dans le cadre de ces TPs sont des fichiers au format CSV ayant les caractéristiques suivantes:
* Point virgule (";") comme séparateur de champs
* Point (".") comme séparateur décimal

## Liste des données: 
* **account**: liste des comptes analytiques
* **category**: liste des catégories
* **currency**: liste des monnaies
* **customer**: liste des clients ayant une carte de fidélité
* **days**: liste des jours de semaine
* **department**: liste des départements de l'enseigne
* **employee**: liste des employés 
* **employee_closure**: 
* **expense**: liste les dépenses
* **inventory**: l'inventaire des livraisons entrepôts/magasin
* **position**: liste des grades des employés
* **product**: liste de tous les produits
* **product_class**: liste tous les classes de produit. Chaque produit appartient à une classe 
* **promotion**: liste toutes les promotions faites sur les produits
* **region**: liste les régions où les magasin sont implantés
* **reserve_employee**: liste des employés de réserve
* **salary**: historique des salaires versés aux employés
* **sales**: liste les ventes effectuées
* **store**: liste les magasin de l'enseigne
* **time_by_day**: liste tous  
* **warehouse**: liste les entrepôts de l'enseigne
* **warehouse_type**: type d'entrepôt

# Spark Core

# Spark DataFrame

# Spark DataSet

# Spark SQL

